{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d933e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (0.35.3)\n",
      "Collecting llama-index\n",
      "  Downloading llama_index-0.14.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (4.57.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (5.1.1)\n",
      "Collecting llama-index-llms-huggingface\n",
      "  Downloading llama_index_llms_huggingface-0.6.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
      "Collecting llama-index-llms-openrouter\n",
      "  Downloading llama_index_llms_openrouter-0.4.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting llama-index-retrievers-bm25\n",
      "  Downloading llama_index_retrievers_bm25-0.6.5-py3-none-any.whl.metadata (446 bytes)\n",
      "Collecting tabula-py\n",
      "  Downloading tabula_py-2.10.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting jpype1\n",
      "  Downloading jpype1-1.6.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (5.0 kB)\n",
      "Collecting pystemmer\n",
      "  Downloading pystemmer-3.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: filelock in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (1.1.10)\n",
      "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.15.0,>=0.14.7 (from llama-index)\n",
      "  Downloading llama_index_core-0.14.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.6.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (3.13.0)\n",
      "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Using cached banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: httpx in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.28.1)\n",
      "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Downloading llama_index_workflows-2.10.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (3.5)\n",
      "Requirement already satisfied: numpy in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.3.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.12.0)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.12.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.9.0)\n",
      "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Downloading wrapt-2.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.22.0)\n",
      "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.1.6)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.7.0)\n",
      "Collecting openai>=1.1.0 (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index)\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting defusedxml>=0.7.1 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting pandas<2.3.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting pypdf<7,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.11.1)\n",
      "Requirement already satisfied: sniffio in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (1.10.1)\n",
      "Collecting llama-index-llms-openai-like<0.6,>=0.5.0 (from llama-index-llms-openrouter)\n",
      "  Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting bm25s>=0.2.7.post1 (from llama-index-retrievers-bm25)\n",
      "  Downloading bm25s-0.2.14-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pystemmer\n",
      "  Downloading PyStemmer-2.2.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: psutil in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from accelerate>=0.26.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (7.1.0)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Using cached llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Downloading wrapt-1.17.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-cloud-services>=0.6.79->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.3.0)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: joblib in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from requests->huggingface-hub) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from requests->huggingface-hub) (2.5.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Downloading greenlet-3.2.4-cp313-cp313-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.26.1)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading llama_index-0.14.7-py3-none-any.whl (7.4 kB)\n",
      "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.14.7-py3-none-any.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_llms_openai-0.6.7-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_readers_file-0.5.4-py3-none-any.whl (51 kB)\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading llama_index_workflows-2.10.3-py3-none-any.whl (91 kB)\n",
      "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_llms_huggingface-0.6.1-py3-none-any.whl (7.8 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
      "Downloading llama_index_llms_openrouter-0.4.2-py3-none-any.whl (4.5 kB)\n",
      "Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl (4.7 kB)\n",
      "Downloading llama_index_retrievers_bm25-0.6.5-py3-none-any.whl (5.0 kB)\n",
      "Downloading PyStemmer-2.2.0.3-cp313-cp313-macosx_11_0_arm64.whl (219 kB)\n",
      "Downloading tabula_py-2.10.0-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jpype1-1.6.0-cp313-cp313-macosx_10_13_universal2.whl (582 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.4/582.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bm25s-0.2.14-py3-none-any.whl (55 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
      "Downloading wrapt-1.17.3-cp313-cp313-macosx_11_0_arm64.whl (39 kB)\n",
      "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
      "Downloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading greenlet-3.2.4-cp313-cp313-macosx_11_0_universal2.whl (272 kB)\n",
      "Using cached aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: striprtf, pystemmer, filetype, dirtyjson, wrapt, soupsieve, pypdf, nltk, jpype1, greenlet, defusedxml, colorama, aiosqlite, pandas, griffe, deprecated, bm25s, beautifulsoup4, tabula-py, openai, llama-index-instrumentation, llama-cloud, banks, llama-index-workflows, llama-index-core, llama-index-retrievers-bm25, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-huggingface, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-huggingface, llama-cloud-services, llama-parse, llama-index-llms-openai-like, llama-index-cli, llama-index-readers-llama-parse, llama-index-llms-openrouter, llama-index\n",
      "\u001b[2K  Attempting uninstall: pandasm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/39\u001b[0m [greenlet]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/39\u001b[0m [greenlet]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/39\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/39\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: openai[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/39\u001b[0m [beautifulsoup4]\n",
      "\u001b[2K    Found existing installation: openai 2.7.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/39\u001b[0m [beautifulsoup4]\n",
      "\u001b[2K    Uninstalling openai-2.7.0:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/39\u001b[0m [openai]up4]\n",
      "\u001b[2K      Successfully uninstalled openai-2.7.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/39\u001b[0m [openai]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/39\u001b[0m [llama-index]\u001b[0m [llama-cloud-services]ile]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiosqlite-0.21.0 banks-2.2.0 beautifulsoup4-4.14.2 bm25s-0.2.14 colorama-0.4.6 defusedxml-0.7.1 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 greenlet-3.2.4 griffe-1.14.0 jpype1-1.6.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.7 llama-index-cli-0.5.3 llama-index-core-0.14.7 llama-index-embeddings-huggingface-0.6.1 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-huggingface-0.6.1 llama-index-llms-openai-0.6.7 llama-index-llms-openai-like-0.5.3 llama-index-llms-openrouter-0.4.2 llama-index-readers-file-0.5.4 llama-index-readers-llama-parse-0.5.1 llama-index-retrievers-bm25-0.6.5 llama-index-workflows-2.10.3 llama-parse-0.6.54 nltk-3.9.2 openai-1.109.1 pandas-2.2.3 pypdf-6.1.3 pystemmer-2.2.0.3 soupsieve-2.8 striprtf-0.0.26 tabula-py-2.10.0 wrapt-1.17.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv huggingface-hub llama-index transformers sentence-transformers llama-index-llms-huggingface llama-index-embeddings-huggingface llama-index-llms-openrouter llama-index-retrievers-bm25 tabula-py  jpype1 pystemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40dc5de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API Key Loaded Successfully: sk-or...94d80\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# RAG Evaluation Notebook\n",
    "# =========================================================\n",
    "# Evaluates RAGIndex retrieval performance using auto-generated question-context pairs\n",
    "# Metrics: MRR, Hit Rate, Precision, Recall, Relevance, Faithfulness\n",
    "# =========================================================\n",
    "\n",
    "from llama_index.core import (Document, Settings)\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openrouter import OpenRouter\n",
    "from dotenv import load_dotenv\n",
    "import os, sys\n",
    "import nest_asyncio\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"✅ API Key Loaded Successfully:\", api_key[:5] + \"...\" + api_key[-5:])\n",
    "else:\n",
    "    print(\"⚠️ API Key is missing! Check your .env file.\")\n",
    "\n",
    "\n",
    "# Initialize OpenRouter LLM\n",
    "llm = OpenRouter(api_key=api_key, model=\"mistralai/mistral-7b-instruct\", max_tokens=512, context_window=4096) # Creates questions and answers\n",
    "Judge_llm = OpenRouter(api_key=api_key, model=\"qwen/qwen-turbo\", max_tokens=512, context_window=4096) # Creates questions and answers\n",
    "Settings.llm = llm\n",
    "\n",
    "# Apply nest_asyncio to fix event loop issues in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set up embedding model\n",
    "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embed_model = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6df62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAG] Total raw documents loaded: 0\n",
      "[RAG] No documents found in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/experiment/data/rag_docs\n",
      "[RAG] Loaded TXT: field_standards.txt (1 docs) [category=field]\n",
      "[RAG] Loaded TXT: mowing_standard.txt (1 docs) [category=mowing]\n",
      "[RAG] Total raw documents loaded: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/rag.py:163: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAG] Loaded existing FAISS index (up-to-date)\n",
      "Loaded 36 chunks from RAG index.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 1: Prepare the documents\n",
    "# ---------------------------------------------------------\n",
    "from pathlib import Path\n",
    "from rag import RAGIndex\n",
    "\n",
    "parent_dir = str(Path(os.getcwd()).parent)\n",
    "project_root = Path(parent_dir)\n",
    "rag_doc_dir = project_root / \"data\" / \"rag_docs\"\n",
    "faiss_dir = project_root / \"data\" / \"faiss_index\"\n",
    "\n",
    "RAG = RAGIndex(str(rag_doc_dir), str(faiss_dir))\n",
    "\n",
    "# Load all document chunks from RAG index into a list\n",
    "# These chunks become the basis for generating test questions\n",
    "docs = []\n",
    "if RAG.mode == \"faiss\" and RAG.vs is not None:\n",
    "    # Loops through every document chunk stored inside the FAISS docstore\n",
    "    for doc in RAG.vs.docstore._dict.values():\n",
    "        # Re-wraps each chunk into your standard Document format (for LlamaIndex evaluation)\n",
    "        docs.append(Document(text=doc.page_content, metadata=doc.metadata))\n",
    "elif RAG.mode == \"bm25\" and RAG.retriever is not None:\n",
    "    for doc in RAG.retriever.docstore:\n",
    "        docs.append(Document(text=doc.page_content, metadata=doc.metadata))\n",
    "print(f\"Loaded {len(docs)} chunks from RAG index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6cd54bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 36 nodes (preserving RAG's original 900-char chunks)\n",
      "   First node length: 839 chars\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 2: Prepare nodes from RAG's ORIGINAL chunks\n",
    "# ---------------------------------------------------------\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "# Converts 'Document' objects to `TextNode` objects\n",
    "# This preserves the exact 900-char chunks your RAG uses\n",
    "nodes = []\n",
    "for i, doc in enumerate(docs):\n",
    "    node = TextNode(\n",
    "        text=doc.text,\n",
    "        metadata=doc.metadata,\n",
    "        # Let LlamaIndex generate IDs naturally\n",
    "    )\n",
    "    nodes.append(node)\n",
    "\n",
    "print(f\"✅ Created {len(nodes)} nodes (preserving RAG's original 900-char chunks)\")\n",
    "print(f\"   First node length: {len(nodes[0].get_content())} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b183a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:43<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 36 question-context pairs\n",
      "   Corpus size: 36 chunks\n",
      "   First corpus text length: 839 chars\n",
      "\n",
      "=== Verification ===\n",
      "✅ Corpus text MATCHES RAG chunks perfectly!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 3: Auto-generate question–context pairs\n",
    "# ---------------------------------------------------------\n",
    "from llama_index.core.evaluation import generate_question_context_pairs\n",
    "\n",
    "qa_dataset = generate_question_context_pairs(\n",
    "    nodes=nodes,\n",
    "    llm=llm,  # OpenRouter mistral-7b-instruct model\n",
    "    num_questions_per_chunk=1,  # can change to 1–3 for speed\n",
    ")\n",
    "\n",
    "qa_data_dict = qa_dataset.model_dump()\n",
    "\n",
    "print(f\"✅ Generated {len(qa_dataset.queries)} question-context pairs\")\n",
    "print(f\"   Corpus size: {len(qa_data_dict['corpus'])} chunks\")\n",
    "print(f\"   First corpus text length: {len(list(qa_data_dict['corpus'].values())[0])} chars\")\n",
    "\n",
    "# Verify corpus matches RAG chunks\n",
    "print(\"\\n=== Verification ===\")\n",
    "sample_corpus_text = list(qa_data_dict[\"corpus\"].values())[0]\n",
    "sample_rag_text = docs[0].text.strip()\n",
    "\n",
    "if sample_corpus_text.strip() == sample_rag_text:\n",
    "    print(\"✅ Corpus text MATCHES RAG chunks perfectly!\")\n",
    "elif sample_corpus_text in sample_rag_text or sample_rag_text in sample_corpus_text:\n",
    "    print(\"⚠️  Corpus text partially matches RAG chunks\")\n",
    "    print(f\"   Corpus length: {len(sample_corpus_text)}\")\n",
    "    print(f\"   RAG length: {len(sample_rag_text)}\")\n",
    "else:\n",
    "    print(\"❌ Corpus text DOES NOT match RAG chunks\")\n",
    "    print(f\"   Corpus preview: {sample_corpus_text[:100]}\")\n",
    "    print(f\"   RAG preview: {sample_rag_text[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f7ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created automatic retriever for FAISS system\n",
      "\n",
      "======================================================================\n",
      "RETRIEVAL METRICS (Automatic Evaluation)\n",
      "======================================================================\n",
      "\n",
      "Metric          Score     \n",
      "-------------------------\n",
      "MRR             0.8426\n",
      "HIT_RATE        0.9167\n",
      "PRECISION       0.2292\n",
      "RECALL          0.9167\n",
      "\n",
      "Evaluated 36/36 queries\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Step 4: Automatic Evaluation\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import NodeWithScore, TextNode, QueryBundle\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "from typing import List\n",
    "\n",
    "# ===================================================================\n",
    "# Wrapper: Makes YOUR RAG.retrieve() compatible with LlamaIndex\n",
    "# ===================================================================\n",
    "\n",
    "class DirectRAGRetriever(BaseRetriever):\n",
    "    \"\"\"Wrapper for YOUR RAG system\"\"\"\n",
    "    \n",
    "    def __init__(self, rag_obj, corpus_text_to_id, top_k=4):\n",
    "        self._rag = rag_obj\n",
    "        self._text_to_id = corpus_text_to_id\n",
    "        self._top_k = top_k\n",
    "        super().__init__()\n",
    "    \n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        # Call YOUR RAG\n",
    "        hits = self._rag.retrieve(query_bundle.query_str, k=self._top_k)\n",
    "        \n",
    "        # Convert to LlamaIndex nodes with corpus IDs\n",
    "        nodes = []\n",
    "        for hit in hits:\n",
    "            text = hit.get(\"text\", \"\").strip()\n",
    "            corpus_id = self._text_to_id.get(text)\n",
    "            \n",
    "            if corpus_id:  # Only add if ID mapping succeeds\n",
    "                node = TextNode(text=text, id_=corpus_id, metadata=hit)\n",
    "                nodes.append(NodeWithScore(node=node, score=hit.get(\"score\", 0.0)))\n",
    "        \n",
    "        return nodes\n",
    "\n",
    "# Build ID mapping\n",
    "corpus_text_to_id = {text: cid for cid, text in qa_data_dict[\"corpus\"].items()}\n",
    "\n",
    "# Create retriever\n",
    "retriever = DirectRAGRetriever(RAG, corpus_text_to_id, top_k=4)\n",
    "\n",
    "print(f\"✅ Created automatic retriever for {RAG.mode.upper()} system\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"RETRIEVAL METRICS (Automatic Evaluation)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\", \"precision\", \"recall\"],\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "eval_results = await evaluator.aevaluate_dataset(qa_dataset)\n",
    "retrieval_df = pd.DataFrame([r.metric_vals_dict for r in eval_results if r.metric_vals_dict])\n",
    "\n",
    "print(f\"\\n{'Metric':<15} {'Score':<10}\")\n",
    "print(\"-\" * 25)\n",
    "for metric in [\"mrr\", \"hit_rate\", \"precision\", \"recall\"]:\n",
    "    print(f\"{metric.upper():<15} {retrieval_df[metric].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nEvaluated {len(retrieval_df)}/{len(qa_dataset.queries)} queries\")\n",
    "\n",
    "# # Save\n",
    "# retrieval_df.to_csv(\"your_rag_retrieval_auto.csv\", index=False)\n",
    "# print(\"✅ Saved to 'your_rag_retrieval_auto.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
