{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d933e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (0.35.3)\n",
      "Requirement already satisfied: llama-index in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (0.14.7)\n",
      "Requirement already satisfied: transformers in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (4.57.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (5.1.1)\n",
      "Requirement already satisfied: llama-index-llms-huggingface in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (0.6.1)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (0.6.1)\n",
      "Requirement already satisfied: llama-index-llms-openrouter in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (0.4.2)\n",
      "Requirement already satisfied: llama-index-retrievers-bm25 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (0.6.5)\n",
      "Requirement already satisfied: tabula-py in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (2.10.0)\n",
      "Requirement already satisfied: jpype1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (1.6.0)\n",
      "Requirement already satisfied: pystemmer in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (2.2.0.3)\n",
      "Requirement already satisfied: filelock in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from huggingface-hub) (1.1.10)\n",
      "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.7 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index) (0.14.7)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index) (0.9.4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index) (0.6.7)\n",
      "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index) (0.5.4)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index) (3.9.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (3.13.0)\n",
      "Requirement already satisfied: aiosqlite in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (1.2.0)\n",
      "Requirement already satisfied: httpx in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.10.3)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (3.5)\n",
      "Requirement already satisfied: numpy in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.3.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.12.0)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.12.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.22.0)\n",
      "Requirement already satisfied: griffe in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.1.6)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.109.1)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.14.2)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: pandas<2.3.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<7,>=5.1.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.1.3)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.11.1)\n",
      "Requirement already satisfied: sniffio in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (1.10.1)\n",
      "Requirement already satisfied: llama-index-llms-openai-like<0.6,>=0.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-llms-openrouter) (0.5.3)\n",
      "Requirement already satisfied: bm25s>=0.2.7.post1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-retrievers-bm25) (0.2.14)\n",
      "Requirement already satisfied: psutil in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from accelerate>=0.26.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (7.1.0)\n",
      "Requirement already satisfied: llama-cloud==0.1.35 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.54 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.3.0)\n",
      "Requirement already satisfied: joblib in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from requests->huggingface-hub) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from requests->huggingface-hub) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.2.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.26.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/Yibing/Desktop/01 NEU/CS7980/capstone_mvp/capstone_venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv huggingface-hub llama-index transformers sentence-transformers llama-index-llms-huggingface llama-index-embeddings-huggingface llama-index-llms-openrouter llama-index-retrievers-bm25 tabula-py  jpype1 pystemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc5de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API Key Loaded Successfully: sk-or...94d80\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# RAG Evaluation Notebook\n",
    "# =========================================================\n",
    "# Evaluates RAGIndex retrieval performance using auto-generated question-context pairs\n",
    "# Metrics: MRR, Hit Rate, Precision, Recall, Faithfulness, Relevancy\n",
    "# =========================================================\n",
    "\n",
    "from llama_index.core import (Document, Settings)\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openrouter import OpenRouter\n",
    "from dotenv import load_dotenv\n",
    "import os, sys\n",
    "import nest_asyncio\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"✅ API Key Loaded Successfully:\", api_key[:5] + \"...\" + api_key[-5:])\n",
    "else:\n",
    "    print(\"⚠️ API Key is missing! Check your .env file.\")\n",
    "\n",
    "\n",
    "# Initialize OpenRouter LLM\n",
    "llm = OpenRouter(api_key=api_key, model=\"mistralai/mistral-7b-instruct\", max_tokens=512, context_window=4096) # Creates questions and answers\n",
    "Judge_llm = OpenRouter(api_key=api_key, model=\"qwen/qwen-turbo\", max_tokens=512, context_window=4096) # Creates questions and answers\n",
    "Settings.llm = llm\n",
    "\n",
    "# Apply nest_asyncio to fix event loop issues in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set up embedding model\n",
    "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embed_model = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a6df62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAG] Loaded TXT: activity_frequency.txt (1 docs) [category=activity]\n",
      "[RAG] Loaded TXT: field_standards.txt (1 docs) [category=field]\n",
      "[RAG] Loaded TXT: mowing_standard.txt (1 docs) [category=mowing]\n",
      "[RAG] Total raw documents loaded: 3\n",
      "[RAG] Loaded existing FAISS index (up-to-date)\n",
      "Loaded 44 chunks from RAG index.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 1: Prepare the documents\n",
    "# ---------------------------------------------------------\n",
    "from pathlib import Path\n",
    "from rag import RAGIndex\n",
    "\n",
    "parent_dir = str(Path(os.getcwd()).parent)\n",
    "project_root = Path(parent_dir)\n",
    "rag_doc_dir = project_root / \"data\" / \"rag_docs\"\n",
    "faiss_dir = project_root / \"data\" / \"faiss_index\"\n",
    "\n",
    "RAG = RAGIndex(str(rag_doc_dir), str(faiss_dir))\n",
    "\n",
    "# Load all document chunks from RAG index into a list\n",
    "# These chunks become the basis for generating test questions\n",
    "docs = []\n",
    "if RAG.mode == \"faiss\" and RAG.vs is not None:\n",
    "    # Loops through every document chunk stored inside the FAISS docstore\n",
    "    for doc in RAG.vs.docstore._dict.values():\n",
    "        # Re-wraps each chunk into standard Document format (for LlamaIndex evaluation)\n",
    "        docs.append(Document(text=doc.page_content, metadata=doc.metadata))\n",
    "elif RAG.mode == \"bm25\" and RAG.retriever is not None:\n",
    "    for doc in RAG.retriever.docstore:\n",
    "        docs.append(Document(text=doc.page_content, metadata=doc.metadata))\n",
    "print(f\"Loaded {len(docs)} chunks from RAG index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6cd54bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 44 nodes (preserving RAG's original 900-char chunks)\n",
      "   First node length: 900 chars\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 2: Prepare nodes from RAG's ORIGINAL chunks\n",
    "# ---------------------------------------------------------\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "# Converts 'Document' objects to `TextNode` objects\n",
    "# This preserves the exact 900-char chunks RAG uses\n",
    "nodes = []\n",
    "for i, doc in enumerate(docs):\n",
    "    node = TextNode(\n",
    "        text=doc.text,\n",
    "        metadata=doc.metadata,\n",
    "        # Let LlamaIndex generate IDs naturally\n",
    "    )\n",
    "    nodes.append(node)\n",
    "\n",
    "print(f\"✅ Created {len(nodes)} nodes (preserving RAG's original 900-char chunks)\")\n",
    "print(f\"   First node length: {len(nodes[0].get_content())} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b183a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [01:33<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 86 question-context pairs\n",
      "   Corpus size: 44 chunks\n",
      "   First corpus text length: 900 chars\n",
      "\n",
      "=== Verification ===\n",
      "✅ Corpus text MATCHES RAG chunks perfectly!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 3: Auto-generate question–context pairs\n",
    "# ---------------------------------------------------------\n",
    "from llama_index.core.evaluation import generate_question_context_pairs\n",
    "\n",
    "qa_dataset = generate_question_context_pairs(\n",
    "    nodes=nodes,\n",
    "    llm=llm,  # OpenRouter mistral-7b-instruct model\n",
    "    num_questions_per_chunk=2,  # can change to 1–3 for speed\n",
    ")\n",
    "\n",
    "qa_data_dict = qa_dataset.model_dump()\n",
    "\n",
    "print(f\"✅ Generated {len(qa_dataset.queries)} question-context pairs\")\n",
    "print(f\"   Corpus size: {len(qa_data_dict['corpus'])} chunks\")\n",
    "print(f\"   First corpus text length: {len(list(qa_data_dict['corpus'].values())[0])} chars\")\n",
    "\n",
    "# Verify corpus matches RAG chunks\n",
    "print(\"\\n=== Verification ===\")\n",
    "sample_corpus_text = list(qa_data_dict[\"corpus\"].values())[0]\n",
    "sample_rag_text = docs[0].text.strip()\n",
    "\n",
    "if sample_corpus_text.strip() == sample_rag_text:\n",
    "    print(\"✅ Corpus text MATCHES RAG chunks perfectly!\")\n",
    "elif sample_corpus_text in sample_rag_text or sample_rag_text in sample_corpus_text:\n",
    "    print(\"⚠️  Corpus text partially matches RAG chunks\")\n",
    "    print(f\"   Corpus length: {len(sample_corpus_text)}\")\n",
    "    print(f\"   RAG length: {len(sample_rag_text)}\")\n",
    "else:\n",
    "    print(\"❌ Corpus text DOES NOT match RAG chunks\")\n",
    "    print(f\"   Corpus preview: {sample_corpus_text[:100]}\")\n",
    "    print(f\"   RAG preview: {sample_rag_text[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1f7ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created automatic retriever for FAISS system\n",
      "\n",
      "======================================================================\n",
      "RETRIEVAL METRICS (Automatic Evaluation)\n",
      "======================================================================\n",
      "\n",
      "Metric          Score     \n",
      "-------------------------\n",
      "MRR             0.7209\n",
      "HIT_RATE        0.8023\n",
      "PRECISION       0.4012\n",
      "RECALL          0.8023\n",
      "\n",
      "Evaluated 86/86 queries\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Step 4: Automatic Evaluation\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import NodeWithScore, TextNode, QueryBundle\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "from typing import List\n",
    "\n",
    "# ===================================================================\n",
    "# Wrapper: Makes RAG.retrieve() compatible with LlamaIndex\n",
    "# ===================================================================\n",
    "\n",
    "class DirectRAGRetriever(BaseRetriever):\n",
    "    \"\"\"Wrapper for RAG system\"\"\"\n",
    "    \n",
    "    def __init__(self, rag_obj, corpus_text_to_id, top_k=2):\n",
    "        self._rag = rag_obj\n",
    "        self._text_to_id = corpus_text_to_id\n",
    "        self._top_k = top_k\n",
    "        super().__init__()\n",
    "    \n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        # Call RAG\n",
    "        hits = self._rag.retrieve(query_bundle.query_str, k=self._top_k)\n",
    "        \n",
    "        # Convert to LlamaIndex nodes with corpus IDs\n",
    "        nodes = []\n",
    "        for hit in hits:\n",
    "            text = hit.get(\"text\", \"\").strip()\n",
    "            corpus_id = self._text_to_id.get(text)\n",
    "            \n",
    "            if corpus_id:  # Only add if ID mapping succeeds\n",
    "                node = TextNode(text=text, id_=corpus_id, metadata=hit)\n",
    "                nodes.append(NodeWithScore(node=node, score=hit.get(\"score\", 0.0)))\n",
    "        \n",
    "        return nodes\n",
    "\n",
    "# Build ID mapping\n",
    "corpus_text_to_id = {text: cid for cid, text in qa_data_dict[\"corpus\"].items()}\n",
    "\n",
    "# Create retriever\n",
    "retriever = DirectRAGRetriever(RAG, corpus_text_to_id, top_k=2)\n",
    "\n",
    "print(f\"✅ Created automatic retriever for {RAG.mode.upper()} system\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"RETRIEVAL METRICS (Automatic Evaluation)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\", \"precision\", \"recall\"],\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "eval_results = await evaluator.aevaluate_dataset(qa_dataset)\n",
    "retrieval_df = pd.DataFrame([r.metric_vals_dict for r in eval_results if r.metric_vals_dict])\n",
    "\n",
    "print(f\"\\n{'Metric':<15} {'Score':<10}\")\n",
    "print(\"-\" * 25)\n",
    "for metric in [\"mrr\", \"hit_rate\", \"precision\", \"recall\"]:\n",
    "    print(f\"{metric.upper():<15} {retrieval_df[metric].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nEvaluated {len(retrieval_df)}/{len(qa_dataset.queries)} queries\")\n",
    "\n",
    "# # Save\n",
    "# retrieval_df.to_csv(\"rag_retrieval_auto.csv\", index=False)\n",
    "# print(\"✅ Saved to 'rag_retrieval_auto.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179bab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GENERATION METRICS (Faithfulness & Relevancy)\n",
      "======================================================================\n",
      "\n",
      "✅ Created RetrieverQueryEngine with FAISS retriever\n",
      "\n",
      "Evaluating responses...\n",
      "(Processing 86 questions)\n",
      "\n",
      "Progress: 0/86\n",
      "Progress: 10/86\n",
      "Progress: 20/86\n",
      "Progress: 30/86\n",
      "Progress: 40/86\n",
      "Progress: 50/86\n",
      "Progress: 60/86\n",
      "Progress: 70/86\n",
      "Progress: 80/86\n",
      "\n",
      "======================================================================\n",
      "RESULTS\n",
      "======================================================================\n",
      "\n",
      "Metric               Score      Min        Max       \n",
      "--------------------------------------------------\n",
      "Faithfulness         0.9651     0.0000     1.0000\n",
      "Relevancy            0.6744     0.0000     1.0000\n",
      "\n",
      "Evaluated: 86/86 queries\n",
      "Low-scoring (<0.5): 28\n",
      "\n",
      "=== Sample Low-Scoring Responses ===\n",
      "\n",
      "1. Query: What is the primary difference between the tasks described in \"Paper Picking\" (1...\n",
      "   Answer:  The primary difference between \"Paper Picking\" (115) and \"Regular Maintenance\" (120) lies in their descriptions and frequencies. \"Paper Picking\" involves the manual removal of litter and small debris...\n",
      "   Scores: Faithfulness=1.00, Relevancy=0.00\n",
      "   Sources used: 2\n",
      "\n",
      "2. Query: How often is the Beach Cleanup (Task 290) performed during the summer, and what ...\n",
      "   Answer:  The Beach Cleanup (Task 285) is performed weekly during the summer. Activities excluded from this task include log removal and sand screening....\n",
      "   Scores: Faithfulness=1.00, Relevancy=0.00\n",
      "   Sources used: 2\n",
      "\n",
      "3. Query: Answer: Every 2 weeks for brushing and debris removal, and the additional task i...\n",
      "   Answer:  The frequency for brushing and debris removal is every 10 working days. Additionally, infill leveling and cleaning are included as part of the maintenance tasks....\n",
      "   Scores: Faithfulness=1.00, Relevancy=0.00\n",
      "   Sources used: 2\n",
      "\n",
      "✅ Saved to 'generation_metrics.csv'\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Step 5: Faithfulness & Relevancy with RetrieverQueryEngine\n",
    "# =========================================================\n",
    "\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.evaluation import FaithfulnessEvaluator, RelevancyEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATION METRICS (Faithfulness & Relevancy)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Create RetrieverQueryEngine\n",
    "# This combines your retriever + LLM into a complete RAG pipeline\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=retriever,  # Your DirectRAGRetriever from earlier\n",
    "    llm=llm,  # Your OpenRouter LLM\n",
    "    response_mode=\"compact\",  # How to combine retrieved chunks\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Created RetrieverQueryEngine with {RAG.mode.upper()} retriever\")\n",
    "\n",
    "# Step 2: Initialize evaluators\n",
    "faithfulness_evaluator = FaithfulnessEvaluator(llm=Judge_llm)\n",
    "relevancy_evaluator = RelevancyEvaluator(llm=Judge_llm)\n",
    "\n",
    "# Step 3: Evaluate each query\n",
    "faithfulness_scores = []\n",
    "relevancy_scores = []\n",
    "failed_queries = []\n",
    "\n",
    "print(\"\\nEvaluating responses...\")\n",
    "print(f\"(Processing {len(qa_dataset.queries)} questions)\\n\")\n",
    "\n",
    "for i, (query_id, query_text) in enumerate(qa_dataset.queries.items()):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Progress: {i}/{len(qa_dataset.queries)}\")\n",
    "    \n",
    "    try:\n",
    "        # Query the engine - handles retrieval + answer generation\n",
    "        response = query_engine.query(query_text)\n",
    "        \n",
    "        # OPTION 1: Pass Response object directly (evaluators extract contexts automatically)\n",
    "        faith_result = faithfulness_evaluator.evaluate_response(\n",
    "            query=query_text,\n",
    "            response=response  # Just pass the response object\n",
    "        )\n",
    "        faith_score = faith_result.score if faith_result.score is not None else 0.0\n",
    "        faithfulness_scores.append(faith_score)\n",
    "        \n",
    "        rel_result = relevancy_evaluator.evaluate_response(\n",
    "            query=query_text,\n",
    "            response=response  # Just pass the response object\n",
    "        )\n",
    "        rel_score = rel_result.score if rel_result.score is not None else 0.0\n",
    "        relevancy_scores.append(rel_score)\n",
    "        \n",
    "        # Track low-scoring queries\n",
    "        if faith_score < 0.5 or rel_score < 0.5:\n",
    "            failed_queries.append({\n",
    "                \"query\": query_text,\n",
    "                \"answer\": str(response)[:200],\n",
    "                \"faithfulness\": faith_score,\n",
    "                \"relevancy\": rel_score,\n",
    "                \"faith_feedback\": getattr(faith_result, 'feedback', ''),\n",
    "                \"rel_feedback\": getattr(rel_result, 'feedback', ''),\n",
    "                \"num_sources\": len(response.source_nodes)\n",
    "            })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error on query {i}: {str(e)}\")\n",
    "        faithfulness_scores.append(0.0)\n",
    "        relevancy_scores.append(0.0)\n",
    "        continue\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if faithfulness_scores and relevancy_scores:\n",
    "    print(f\"\\n{'Metric':<20} {'Score':<10} {'Min':<10} {'Max':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Faithfulness':<20} {sum(faithfulness_scores)/len(faithfulness_scores):.4f}     \"\n",
    "          f\"{min(faithfulness_scores):.4f}     {max(faithfulness_scores):.4f}\")\n",
    "    print(f\"{'Relevancy':<20} {sum(relevancy_scores)/len(relevancy_scores):.4f}     \"\n",
    "          f\"{min(relevancy_scores):.4f}     {max(relevancy_scores):.4f}\")\n",
    "    \n",
    "    print(f\"\\nEvaluated: {len(faithfulness_scores)}/{len(qa_dataset.queries)} queries\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame({\n",
    "        \"query\": list(qa_dataset.queries.values())[:len(faithfulness_scores)],\n",
    "        \"faithfulness\": faithfulness_scores,\n",
    "        \"relevancy\": relevancy_scores,\n",
    "    })\n",
    "    results_df.to_csv(\"generation_metrics.csv\", index=False)\n",
    "    print(\"\\n✅ Saved to 'generation_metrics.csv'\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No results to display - check for errors above\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
